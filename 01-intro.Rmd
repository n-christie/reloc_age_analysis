# Overview of Registers and Data

The study period in Register RELOC-AGE ranges from 1990-2020 and is comprised of 13 registers with staggered coverage which is here illustrated.  

```{r,out.width="100%"}

knitr::include_graphics(here("output/figures", "timeline_registers_update.png"))
```


The table below gives a description of the various registers,
noting the types of variables contained within.

```{r}

register_tbl <- readRDS( here("output/tables", "register_tbl.rds") )

 kable(register_tbl,
      "html",
      caption = "Register descriptions",
      linesep = "",
      booktabs = TRUE,
      align = "ll",
      escape=FALSE) %>% 
  kable_styling(bootstrap_options = c( "responsive"), font_size = 11) %>%
    scroll_box(width = "800px", height = "500px")


```

## Description of data sets from SCB

A large amount of data from the registrars is accessed through Statistics Sweden (SCB).  This data is delivered in text format (file extension .txt), and is partitioned, for the most part, into individual files separated by both year and grouped data set.  While the data contained in this data originates from the specified data Registrars previously outlined, the data is received from SCB consolidated and grouped into various data sets which require further cleaning and processing.  These grouped data sets are described below. 


### Dataset overview


Most of the descriptive data comes from LISA (lev_lisa in the table below), with more than 5 million individuals, over 128 million individual-year observations, and 95 variables across 30 years.  The coverage of the other data sets is also documented, with linking of data sets possible by matching on a individual's unique identifier, Lopnr.

```{r}


df_registers <- readRDS(here("output/tables", "register_obs.rds"))
df_reg_time <- readRDS(here("output/tables", "register_obs_time.rds")) %>% 
  mutate(X1987 = if_else(Register == "lev_partners_RTB", "5108973",
                         if_else(Register == "lev_samh", "3092138", "-")))
  


 kable(df_registers,
      "html",
      caption = "Dataset descriptions",
      linesep = "",
      booktabs = TRUE,
      align = "ll",
      col.names = c("Dataset", "First year", "Last year", "Obs", "No. Variables", "Unique ids"),
      escape=FALSE) %>% 
  kable_styling(bootstrap_options = c( "responsive", "hover"), font_size = 11) 
 


```


In joining data sets, the number of unique individuals resultant in the final data set may vary depending on the coverage of specific variables in each data source.
Nonetheless, it may be informational to see the number of unique individuals represented in each data set over time to get an idea of the coverage.
The table below tallies the number of unique individuals found in each year of each data set.



```{r}

  kable(df_reg_time,
      "html",
      caption = "Observations over time",
      linesep = "",
      booktabs = TRUE,
      align = "ll",
      escape=FALSE,
      col.names = c("Dataset", paste(1987:2020))) %>% 
  kable_styling(bootstrap_options = c( "responsive"), font_size = 11) %>%
    scroll_box(width = "800px", height = "500px")




```

To better gauge the number of individuals after a typical joining of data sets,
here we show the number of individuals overtime and sex belonging to the LISA data set, matched with the unique individuals of the population data set.

```{r,out.width="100%"}

knitr::include_graphics(here("output/figures", "n_sex_time.png"))
```


### Data cleaning and joining of raw data

As illustrated above, the data from RELOC-AGE is comprised of from several registers and sources.  In order to arrive at the final data set, a number of data cleaning actions, multiple joins, and many quality control steps have been taken to insure reliable analysis and data integrity.  This section details steps taken.

With data covering about 3 million individuals over decades and with a multitude of variables spread out across hundreds of very large files, the computational effort to complete these tasks are very time intensive, often taking hours for a large merge, with progress occasionally hindered by computational restrictions and small errors which arise in the data cleaning process.  With this in mind, detailed documentation, contained both here and alongside code used in the data cleaning, is prioritized to reduce any need to repeat these time-intensive processes. 

As a first step, the following initial data cleaning is performed:


* Raw data files are organized into folder structure where each folder contains all data from a particular data set.
* An individual script for each data set is written in R that reads the raw yearly .txt files and merges files into one data set.
* When required, a variable "year" is generated in the joined data set specifying which year the data originates from( taken from the name of the .txt file).
* Variables are renamed into lowercase with spaces and other delimiters transformed into underscores ( _ ) for consistent naming conventions and avoidance of future merge conflicts.
* The joined and cleaned data set is saved in the contained folder in both R's .rds and Stata's .dta formats.
* A README.txt file is created in each folder documenting the process.

The result consists of eleven folders each containing a data set's respective raw data, a documented R merging/cleaning script for full reproducibility, and a merged data set in both R and Stata format to be used in subsequent merging and further analysis.

```{r,out.width="100%"}

knitr::include_graphics(here("output/figures", "folder_structure.png"))
```


